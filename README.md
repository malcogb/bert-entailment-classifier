# BERT Entailment Classifier

Ce projet implÃ©mente un modÃ¨le de classification d'entailment basÃ© sur BERT.

## Structure du projet

```
.
â”œâ”€â”€ train.py              # Script d'entraÃ®nement
â”œâ”€â”€ model.py              # DÃ©finition du modÃ¨le BERTClassifier
â”œâ”€â”€ demo.py               # Interface Gradio pour tester le modÃ¨le
â”œâ”€â”€ requirements.txt      # DÃ©pendances Python
â”œâ”€â”€ saved_model.pt        # Fichier pour sauvegarder les checkpoints
â””â”€â”€ README.md             # Ce fichier explique ce projet
```

## Lancer l'entraÃ®nement

AprÃ¨s avoir installÃ© les dÃ©pendances :

```bash
pip install -r requirements.txt
```

Puis exÃ©cutez :

```bash
python train.py
```

## Test via Gradio

Lancez le fichier `demo.py` pour ouvrir lâ€™interface utilisateur :

```bash
python demo.py
```

## DÃ©tails du modÃ¨le

- ModÃ¨le utilisÃ© : `bert-base-multilingual-cased`
- Tokenizer : `AutoTokenizer`
- max_length : `259` cette valeur constitue le max_length de notre dataset
- batch_size : `16`
- Optimiseur : `Adam`
- Loss : `CrossEntropyLoss`

## Suivi des performances

Les mÃ©triques (accuracy, loss) sont suivies via [Weights & Biases](https://wandb.ai/).

## DonnÃ©es

Le fichier `train_6.csv` est utilisÃ© comme dataset principal avec trois labels :
- 0 : entailment
- 1 : contradiction
- 2 : neutral

## Auteur

Projet dÃ©veloppÃ© avec ğŸ’» et â˜• par Malco GBAKPA.
